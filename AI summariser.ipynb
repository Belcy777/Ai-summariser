{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_eNGbj7Gp37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39584da5-2552-4f5b-ff29-d2c8a15eac74"
      },
     
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3WLG3GS5K2o",
        "outputId": "ec314c6c-73b2-455a-de78-00cc0ab75aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 1\n",
        "!pip install -q google-genai gradio PyPDF2 python-docx reportlab pydub SpeechRecognition"
      ],
      "metadata": {
        "id": "Fc67HrdvOxDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bcfbb8d-d457-488f-d331-bebb8d653cc7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 2a - quick (do not hardcode in shared notebooks)\n",
        "import os\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyDUApDivb8JsJV68XKGpQe4ahRqwf2nvRI\"\n"
      ],
      "metadata": {
        "id": "sbwqiLkWPLXw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 2b - interactive (recommended)\n",
        "# from getpass import getpass\n",
        "# import os\n",
        "# key = getpass(\"Paste your Google Gemini API key from Google AI Studio: \")\n",
        "# os.environ[\"GEMINI_API_KEY\"] = key\n"
      ],
      "metadata": {
        "id": "tNiuprJPPR0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 3 - Full app\n",
        "import os\n",
        "import tempfile\n",
        "import gradio as gr\n",
        "from google import generativeai  # google-genai SDK\n",
        "from PyPDF2 import PdfReader\n",
        "from docx import Document\n",
        "from reportlab.pdfgen import canvas\n",
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr\n",
        "\n",
        "# Configure Gemini SDK\n",
        "API_KEY = os.environ.get(\"GEMINI_API_KEY\") or os.environ.get(\"GOOGLE_API_KEY\") or os.environ.get(\"GEMINI_KEY\")\n",
        "if not API_KEY:\n",
        "    raise RuntimeError(\"Set GEMINI_API_KEY environment variable (see earlier cell).\")\n",
        "# configure generativeai with the API key\n",
        "generativeai.configure(api_key=API_KEY)\n",
        "\n",
        "# ---------- helpers ----------\n",
        "def pdf_to_text(path):\n",
        "    reader = PdfReader(path)\n",
        "    parts = []\n",
        "    for page in reader.pages:\n",
        "        p = page.extract_text()\n",
        "        if p:\n",
        "            parts.append(p)\n",
        "    return \"\\n\\n\".join(parts)\n",
        "\n",
        "def docx_to_text(path):\n",
        "    doc = Document(path)\n",
        "    paragraphs = [p.text for p in doc.paragraphs if p.text.strip()]\n",
        "    return \"\\n\\n\".join(paragraphs)\n",
        "\n",
        "def audio_to_text(audio_filepath):\n",
        "    \"\"\"Convert audio file to WAV and run Google-recognizer (via speech_recognition).\"\"\"\n",
        "    if audio_filepath is None:\n",
        "        return \"\"\n",
        "    try:\n",
        "        wav_path = tempfile.mktemp(suffix=\".wav\")\n",
        "        AudioSegment.from_file(audio_filepath).export(wav_path, format=\"wav\")\n",
        "    except Exception as e:\n",
        "        return f\"[Audio convert error: {e}]\"\n",
        "\n",
        "    r = sr.Recognizer()\n",
        "    try:\n",
        "        with sr.AudioFile(wav_path) as source:\n",
        "            audio_data = r.record(source)\n",
        "        text = r.recognize_google(audio_data)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f\"[Speech-to-text error: {e}]\"\n",
        "\n",
        "def save_text_as_pdf(text, out_path):\n",
        "    c = canvas.Canvas(out_path)\n",
        "    t = c.beginText(40, 800)\n",
        "    t.setFont(\"Helvetica\", 11)\n",
        "    for line in text.split(\"\\n\"):\n",
        "        # basic wrap\n",
        "        if len(line) <= 95:\n",
        "            t.textLine(line)\n",
        "        else:\n",
        "            while len(line) > 95:\n",
        "                t.textLine(line[:95])\n",
        "                line = line[95:]\n",
        "            if line:\n",
        "                t.textLine(line)\n",
        "        if t.getY() < 40:\n",
        "            c.drawText(t)\n",
        "            c.showPage()\n",
        "            t = c.beginText(40, 800)\n",
        "            t.setFont(\"Helvetica\", 11)\n",
        "    c.drawText(t)\n",
        "    c.save()\n",
        "\n",
        "def save_text_as_docx(text, out_path):\n",
        "    doc = Document()\n",
        "    doc.add_heading(\"AI Summary\", level=1)\n",
        "    for line in text.split(\"\\n\"):\n",
        "        doc.add_paragraph(line)\n",
        "    doc.save(out_path)\n",
        "\n",
        "# ---------- Gemini summarization ----------\n",
        "def gemini_summarize(prompt_text, model_name=\"gemini-1.5-mini\", max_output_tokens=512):\n",
        "    \"\"\"\n",
        "    Uses the google-genai SDK to generate a summary.\n",
        "    model_name: choose an available Gemini model like \"gemini-1.5-mini\" or \"gemini-1.5-pro\" if your key allows.\n",
        "    \"\"\"\n",
        "    model = generativeai.GenerativeModel(model_name=model_name)\n",
        "    prompt = (\n",
        "        \"You are a helpful assistant. Summarize the following text into clear, concise, student-friendly bullet points:\\n\\n\"\n",
        "        + prompt_text\n",
        "    )\n",
        "    try:\n",
        "        generation_config = {\n",
        "            \"max_output_tokens\": max_output_tokens,\n",
        "        }\n",
        "        response = model.generate_content(prompt, generation_config=generation_config)\n",
        "        # The response object from generate_content has the text in the 'text' attribute\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"[API error: {e}]\"\n",
        "\n",
        "# ---------- Combined pipeline ----------\n",
        "def process_all(text_input, uploaded_file, audio_file, filename_prefix):\n",
        "    # Gather content\n",
        "    pieces = []\n",
        "    if text_input and text_input.strip():\n",
        "        pieces.append(text_input.strip())\n",
        "\n",
        "    if uploaded_file:\n",
        "        fp = uploaded_file.name\n",
        "        if fp.lower().endswith(\".pdf\"):\n",
        "            pieces.append(pdf_to_text(fp))\n",
        "        elif fp.lower().endswith(\".docx\"):\n",
        "            pieces.append(docx_to_text(fp))\n",
        "        elif fp.lower().endswith(\".txt\"):\n",
        "            try:\n",
        "                pieces.append(uploaded_file.read().decode(\"utf-8\"))\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    voice_text = \"\"\n",
        "    if audio_file:\n",
        "        voice_text = audio_to_text(audio_file)\n",
        "        pieces.append(voice_text)\n",
        "\n",
        "    if not pieces:\n",
        "        return \"No input provided. Type text, upload a file or record via microphone.\", \"\", \"\", \"\"\n",
        "\n",
        "    combined = \"\\n\\n\".join(pieces)\n",
        "\n",
        "    # Chunk long inputs if necessary (simple chunker by characters)\n",
        "    MAX_CHARS = 20000  # adjust if you prefer chunking\n",
        "    if len(combined) <= MAX_CHARS:\n",
        "        summary = gemini_summarize(combined)\n",
        "    else:\n",
        "        # chunk & summarize each then combine\n",
        "        chunks = [combined[i:i+MAX_CHARS] for i in range(0, len(combined), MAX_CHARS)]\n",
        "        partials = []\n",
        "        for i, ch in enumerate(chunks, 1):\n",
        "            partials.append(gemini_summarize(ch))\n",
        "        summary = gemini_summarize(\"\\n\\n\".join(partials))\n",
        "\n",
        "    # Save files with chosen filename_prefix (or default)\n",
        "    safe_prefix = (filename_prefix.strip() or \"summary\").replace(\" \", \"_\")\n",
        "    pdf_path = tempfile.mktemp(suffix=f\"_{safe_prefix}.pdf\")\n",
        "    docx_path = tempfile.mktemp(suffix=f\"_{safe_prefix}.docx\")\n",
        "    save_text_as_pdf(summary, pdf_path)\n",
        "    save_text_as_docx(summary, docx_path)\n",
        "\n",
        "    # Return summary, voice transcript, and download paths\n",
        "    return summary, voice_text, pdf_path, docx_path\n",
        "\n",
        "# ---------- Gradio UI ----------\n",
        "with gr.Blocks(theme=gr.themes.Default()) as demo:\n",
        "    gr.Markdown(\"# ğŸ“š Gemini AI Notes Summarizer\")\n",
        "\n",
        "    with gr.Row():\n",
        "        txt = gr.Textbox(lines=16, label=\"Paste text here\", placeholder=\"Paste long notes, chapters or book sections...\")\n",
        "        summary_box = gr.Textbox(lines=18, label=\"AI Summary\", placeholder=\"Summary will appear here...\")\n",
        "\n",
        "    with gr.Row():\n",
        "        uploaded = gr.File(label=\"Upload File (PDF / DOCX / TXT)\")\n",
        "        voice_transcript = gr.Textbox(lines=6, label=\"Voice Transcript (shows captured speech)\")\n",
        "\n",
        "    audio = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"ğŸ¤ Speak or record (Microphone)\")\n",
        "\n",
        "    filename_prefix = gr.Textbox(label=\"Filename prefix for downloads (no extension)\", value=\"My_Summary\")\n",
        "    btn = gr.Button(\"Generate Summary\")\n",
        "\n",
        "    # outputs: summary, voice transcript, pdf file, docx file\n",
        "    btn.click(fn=process_all, inputs=[txt, uploaded, audio, filename_prefix],\n",
        "              outputs=[summary_box, voice_transcript, gr.File(label=\"Download PDF\"), gr.File(label=\"Download DOCX\")])\n",
        "\n",
        "    gr.Markdown(\"**Notes:**\\n- If you want larger context/window for one-shot book summarization, use larger Gemini models (if your key/project supports them).\\n- The app uses the free Gemini API key created in Google AI Studio. Learn more in the quickstart docs.\")\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "a5Yw6dUoPtsi",
        "outputId": "9eca3eb6-01ea-412a-c3d2-e499a8161071"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py:55: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n",
            "  loader.exec_module(module)\n",
            "/tmp/ipython-input-1968706192.py:155: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=gr.themes.Default()) as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://266cb21dc3aad76ee5.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://266cb21dc3aad76ee5.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}
